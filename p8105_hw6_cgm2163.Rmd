---
title: "Homework 6"
output: github_document
---

## Problem 1

We can upload the birthweight data set after entering the tidyverse, making
sure to clean the data set and convert relevant variables to factors.


```{r}

library(tidyverse)
library(modelr)


birthweight = read.csv("./birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))


```

Next, we can check to see if there are any missing values:

```{r}

sapply(birthweight, function(na) sum(is.na(na)))

```

We can see that there are `r sum(is.na(birthweight))` missing values, so we 
don't need to take any measures to delete rows or cells. There are `r nrow(birthweight)` rows 
and `r ncol(birthweight)` columns.

Now we can make some regression models. In analyzing the variables available in 
the data set, the ones I hypothesize would be the most effective predictors
of birthweight are:
\smoken\: average number of cigarettes smoked per day during pregnancy (mother's
smoking history is a known risk factor for low birthweight, so I would expect
an inverse relationship between cigarettes per day and birthweight in grams)
\gaweeks\: gestational age in weeks (it would logically follow that babies born
earlier in gestation would weigh less)
\malform\: presence of malformations that could affect weight (again, logically
it would track that babies with malformations that would affect weight would be
on the smaller side)



```{r}

reg1 = lm(bwt ~ smoken + gaweeks + malform, data = birthweight)

summary(reg1)

```

We can see above the summary model information for the regression model, but we can also create a plot of the residuals:

```{r}

birthweight %>%
  modelr::add_predictions(reg1) %>%
  modelr::add_residuals(reg1) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() + geom_smooth(color = "blue",
          method = "lm", se = FALSE) + labs(title = "Residuals vs. Predicted",
            x = "Residuals", y = "Predicted values")


```

We can see that the residuals are roughly symmetrical and evenly dispersed 
around y = 0.


We can also work to make some models with other predictors:

```{r}

reg2 = lm(bwt ~ blength + gaweeks, data = birthweight)

summary(reg2)

reg3 = lm(bwt ~ blength * babysex * bhead, data = birthweight)

summary(reg3)

```

Now, we can use the following function to compare and analyze further:

```{r}

cv_bw =
  crossv_mc(birthweight, 100) %>%
  mutate(
    reg1 = map(train, ~lm(bwt ~ smoken + gaweeks + malform, data = .x)),
    reg2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    reg3 = map(train, ~lm(bwt ~ blength * babysex * bhead, data = .x))) %>%
  mutate(
    rmse_reg1 = map2_dbl(.x = reg1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_reg2 = map2_dbl(.x = reg2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_reg3 = map2_dbl(.x = reg3, .y = test, ~rmse(model = .x, data = .y))
  )


cv_bw %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>%
  ggplot(aes(x = model, y = rmse)) + geom_violin(color = "blue")


```


Model 3 has the smallest RMSE, and therefore it is our best choice for the model
we go forward with.


## Problem 2

First, we can use the code chunk on the course website to analyze the NOAA data.

```{r}

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

set.seed(1)

```

We can now use the \bootstrap\ function to analyze this sample.

First, lets check out the log betas of the function

```{r}


# boot strapping log

boot_log = 
 weather_df %>%
  bootstrap(5000, id = "straps") %>%
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    glances = map(models, broom::glance)) %>%
  select(straps, results, glances) %>%
  unnest(results, glances)

# boot log

log_b = 
  boot_log %>%
  select(straps, term, estimate) %>%
  pivot_wider(
    names_from = term,
    values_from = estimate) %>%
  rename(intercept = "(Intercept)") %>%
  mutate(log_betas = log(intercept*tmin))


# boot log plot

log_b %>%
  ggplot(aes(x = log_betas)) + geom_density()  + 
    labs(
      x = "log betas",
      y = "density",
      title = "log beta distribution"
    )

# print log b

log_b %>%
  knitr::kable(digits = 3)
  


```

We can see above that the distribution of our log betas is approximately 
normal.


Now, lets look at our r-square distribution:

```{r}

# boot strapping r square

boot_r_sq = 
  weather_df %>%
  janitor::clean_names() %>%
  modelr::bootstrap(n = 5000, id = "straps") %>%
  mutate(
    model = map(.x = strap, ~lm(tmax ~ tmin, data = .x)))
  

# checking r square

r_square = 
  boot_r_sq %>%
  mutate(
    result = map(model, broom::glance)) %>%
  unnest(result) %>%
  select(r.squared, straps)


# plot r square

r_square %>%
  ggplot(aes(x = r.squared)) + geom_density() + 
    labs(
      x = "r squared",
      y = "density",
      title = "r squared distribution"
    )
  
# print r square 

r_square %>%
  knitr::kable(digits = 3)




```

We can see above that the distribution of our log betas is, similar to our r
square distribution, approximately normal.


```{r}

# confidence interval

weather_df %>%
  bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~tmin, data = .x)),
    results = map(models, broom::glance)) %>%
  select(-strap, -models) %>%
  unnest(results) %>%
  janitor::clean_names() %>%
  summarise(
    lower_ci = quantile(r_squared, c(0.025)),
    upper_ci = quantile(r_squared, c(0.975))) %>%
  knitr::kable(digits = 2)


```


We are 95% confident that the true r-squared value falls between 0.89 and 0.93,
indicating that the model is a good fit for the data.



